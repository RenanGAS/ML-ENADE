{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a2e3ff-80ff-4cd2-a181-5be13523e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f043ec91-b746-4bd5-bf6e-9300b7242b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4878684c-5b69-40aa-9930-4a5db4db8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "enade_treino = pd.read_csv(\"../tabelas_finais/tabela_final_2011_treinamento.csv\")\n",
    "enade_treino[\"origin\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3886c93-a7a4-4333-b524-ff0077857611",
   "metadata": {},
   "outputs": [],
   "source": [
    "enade_teste = pd.read_csv(\"../tabelas_finais/tabela_final_2014_treinamento.csv\")\n",
    "enade_teste[\"origin\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc5a3c0-7887-4998-96dd-40a7e5e0139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codigo_do_Curso</th>\n",
       "      <th>Numero_Notas_Invalidas</th>\n",
       "      <th>Numero_Faltantes</th>\n",
       "      <th>Numero_Participantes</th>\n",
       "      <th>ADS</th>\n",
       "      <th>BCC</th>\n",
       "      <th>EC</th>\n",
       "      <th>GTI</th>\n",
       "      <th>LCC</th>\n",
       "      <th>RC</th>\n",
       "      <th>...</th>\n",
       "      <th>Não sei responder_Plano_de_Ensino</th>\n",
       "      <th>nulos_Formacao</th>\n",
       "      <th>Muito boa_Formacao</th>\n",
       "      <th>Boa_Formacao</th>\n",
       "      <th>Regular_Formacao</th>\n",
       "      <th>Fraca_Formacao</th>\n",
       "      <th>Muito fraca_Formacao</th>\n",
       "      <th>Não sei responder_Formacao</th>\n",
       "      <th>Nota_Conceito_Faixa</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>5001073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5001087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>5001088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>5001103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>5001162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Codigo_do_Curso  Numero_Notas_Invalidas  Numero_Faltantes  \\\n",
       "1500          5001073                     0.0          0.034483   \n",
       "1501          5001087                     0.0          0.130435   \n",
       "1502          5001088                     0.0          0.064516   \n",
       "1503          5001103                     0.0          0.043478   \n",
       "1504          5001162                     0.0          0.422222   \n",
       "\n",
       "      Numero_Participantes  ADS  BCC   EC  GTI  LCC   RC  ...  \\\n",
       "1500              0.965517  0.0  0.0  0.0  0.0  1.0  0.0  ...   \n",
       "1501              0.869565  0.0  0.0  0.0  0.0  1.0  0.0  ...   \n",
       "1502              0.935484  0.0  0.0  0.0  0.0  1.0  0.0  ...   \n",
       "1503              0.956522  0.0  0.0  0.0  0.0  1.0  0.0  ...   \n",
       "1504              0.577778  0.0  0.0  0.0  0.0  1.0  0.0  ...   \n",
       "\n",
       "      Não sei responder_Plano_de_Ensino  nulos_Formacao  Muito boa_Formacao  \\\n",
       "1500                           0.000000        0.000000            0.448276   \n",
       "1501                           0.000000        0.130435            0.173913   \n",
       "1502                           0.016129        0.000000            0.645161   \n",
       "1503                           0.043478        0.000000            0.913043   \n",
       "1504                           0.044444        0.311111            0.311111   \n",
       "\n",
       "      Boa_Formacao  Regular_Formacao  Fraca_Formacao  Muito fraca_Formacao  \\\n",
       "1500      0.344828          0.172414        0.000000              0.034483   \n",
       "1501      0.130435          0.434783        0.043478              0.000000   \n",
       "1502      0.145161          0.161290        0.016129              0.000000   \n",
       "1503      0.043478          0.043478        0.000000              0.000000   \n",
       "1504      0.066667          0.222222        0.066667              0.022222   \n",
       "\n",
       "      Não sei responder_Formacao  Nota_Conceito_Faixa  origin  \n",
       "1500                    0.000000                    3       1  \n",
       "1501                    0.086957                    4       1  \n",
       "1502                    0.032258                    3       1  \n",
       "1503                    0.000000                    2       1  \n",
       "1504                    0.000000                    3       1  \n",
       "\n",
       "[5 rows x 228 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_2017_2021 = pd.concat([enade_treino, enade_teste])\n",
    "\n",
    "# No NannyML parece que não randomiza por causa da separação em chunks\n",
    "#dados_2017_2021 = dados_2017_2021.sample(frac = 1, ignore_index=True)\n",
    "\n",
    "dados_2017_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1868a77f-1381-4285-b978-04e742e94faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_caracteristicas = dados_2017_2021.shape[1] - 1\n",
    "X_enade = dados_2017_2021.iloc[:, 0:numero_caracteristicas]\n",
    "y_enade = dados_2017_2021.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "282b726a-4175-477d-8657-c5c8cef7f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_caracteristicas = enade_treino.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d838c31-0224-4654-9ab9-0d2bc072a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder 0\n",
      "AUC score: 0.909005288705354\n",
      "\n",
      "Folder 1\n",
      "AUC score: 0.8762380848883782\n",
      "\n",
      "Folder 2\n",
      "AUC score: 0.9058382753231699\n",
      "\n",
      "Folder 3\n",
      "AUC score: 0.9110545326585318\n",
      "\n",
      "Folder 4\n",
      "AUC score: 0.8943707889589219\n",
      "\n",
      "Folder 5\n",
      "AUC score: 0.9086326988956852\n",
      "\n",
      "Folder 6\n",
      "AUC score: 0.9203278790325085\n",
      "\n",
      "Folder 7\n",
      "AUC score: 0.8922076981194563\n",
      "\n",
      "Folder 8\n",
      "AUC score: 0.9087154966311671\n",
      "\n",
      "Folder 9\n",
      "AUC score: 0.8953747115016404\n",
      "\n",
      "AUC score Total: 0.9016546092464371\n"
     ]
    }
   ],
   "source": [
    "# NannyML approach\n",
    "\n",
    "stratifiedSplit = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "y_true_splits = []\n",
    "y_score_splits = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratifiedSplit.split(X_enade, y_enade)):\n",
    "    enade_treino = dados_2017_2021.iloc[train_index]\n",
    "    X_enade_treino = enade_treino.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_treino = enade_treino.iloc[:, -1]\n",
    "\n",
    "    enade_teste = dados_2017_2021.iloc[test_index]\n",
    "    X_enade_teste = enade_teste.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_teste = enade_teste.iloc[:, -1]\n",
    "    \n",
    "    normalizador_treinamento = StandardScaler()\n",
    "    normalizador_treinamento.fit(X_enade_treino)\n",
    "    treinamento_normalizado = normalizador_treinamento.transform(X_enade_treino)\n",
    "    \n",
    "    normalizador_teste = StandardScaler()\n",
    "    normalizador_teste.fit(X_enade_teste)\n",
    "    teste_normalizado = normalizador_teste.transform(X_enade_teste)\n",
    "    \n",
    "    # LGBMClassifier é o modelo utilizado na biblioteca NannyML\n",
    "    lgbmClassifier = LGBMClassifier(objective='binary', importance_type='split', boosting_type='gbdt', num_leaves=31, learning_rate=0.05, \n",
    "                                    feature_fraction=0.9, bagging_fraction=0.8, bagging_freq=5, colsample_bytree=None, subsample_freq=None, subsample=None)\n",
    "    lgbmClassifier.fit(treinamento_normalizado, y_enade_treino)\n",
    "            \n",
    "    y_score_teste = lgbmClassifier.predict_proba(teste_normalizado)[:, 1]\n",
    "    \n",
    "    y_true_splits.extend(y_enade_teste)\n",
    "    y_score_splits.extend(y_score_teste)\n",
    "    \n",
    "    print(f\"\\nFolder {i}\")\n",
    "    print(f\"AUC score: {roc_auc_score(y_enade_teste, y_score_teste)}\")\n",
    "\n",
    "result = roc_auc_score(y_true_splits, y_score_splits)\n",
    "print(f\"\\nAUC score Total: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b6904da-dbfd-406c-a75a-172e1870c6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder 0\n",
      "Atributo: nulos_Condicao_Salas\n",
      "\tMédia: 0.773\n",
      "Atributo: Exterior_Tipo_Escola_EM\n",
      "\tMédia: 0.138\n",
      "Atributo: Não sei responder_Dominio_Professores\n",
      "\tMédia: 0.063\n",
      "Atributo: nulos_Disponibilidade_Professores\n",
      "\tMédia: 0.039\n",
      "Atributo: Nota_Conceito_Faixa\n",
      "\tMédia: 0.000\n",
      "AUC score: 0.9757574108999467\n",
      "Drift score: 0.9515148217998934\n",
      "\n",
      "Folder 1\n",
      "Atributo: nulos_Disponibilidade_Professores\n",
      "\tMédia: 0.788\n",
      "Atributo: Exterior_Tipo_Escola_EM\n",
      "\tMédia: 0.149\n",
      "Atributo: Não sei responder_Dominio_Professores\n",
      "\tMédia: 0.054\n",
      "Atributo: nulos_Qtde_Livros\n",
      "\tMédia: 0.009\n",
      "Atributo: nulos_Politica_de_Ingresso\n",
      "\tMédia: 0.001\n",
      "AUC score: 0.973551066299144\n",
      "Drift score: 0.947102132598288\n",
      "\n",
      "Folder 2\n",
      "Atributo: nulos_Condicao_Salas\n",
      "\tMédia: 0.655\n",
      "Atributo: nulos_Qtde_Livros\n",
      "\tMédia: 0.141\n",
      "Atributo: Exterior_Tipo_Escola_EM\n",
      "\tMédia: 0.114\n",
      "Atributo: Não sei responder_Dominio_Professores\n",
      "\tMédia: 0.053\n",
      "Atributo: nulos_Disponibilidade_Professores\n",
      "\tMédia: 0.030\n",
      "AUC score: 0.9737263649112626\n",
      "Drift score: 0.9474527298225253\n",
      "\n",
      "Folder 3\n",
      "Atributo: Nota_Conceito_Faixa\n",
      "\tMédia: nan\n",
      "Atributo: ES_UF_Ensino_Medio\n",
      "\tMédia: nan\n",
      "Atributo: Matutino\n",
      "\tMédia: nan\n",
      "Atributo: Universidade\n",
      "\tMédia: nan\n",
      "Atributo: IFECT\n",
      "\tMédia: nan\n",
      "AUC score: 0.27784527781807633\n",
      "Drift score: 0\n",
      "\n",
      "Folder 4\n",
      "Atributo: nulos_Condicao_Salas\n",
      "\tMédia: 1.000\n",
      "Atributo: Nota_Conceito_Faixa\n",
      "\tMédia: 0.000\n",
      "Atributo: CO\n",
      "\tMédia: 0.000\n",
      "Atributo: Matutino\n",
      "\tMédia: 0.000\n",
      "Atributo: Universidade\n",
      "\tMédia: 0.000\n",
      "AUC score: 0.9745786788529426\n",
      "Drift score: 0.9491573577058852\n",
      "\n",
      "Médias das iterações\n",
      "AUC score: 0.8350917597562745\n",
      "Drift score: 0.7590454083853183\n"
     ]
    }
   ],
   "source": [
    "# Deepchecks approach\n",
    "\n",
    "stratifiedSplit = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "top_3 = [0, 0, 0]\n",
    "media_auc = 0\n",
    "media_drift = 0\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratifiedSplit.split(X_enade, y_enade)):\n",
    "    enade_treino = dados_2017_2021.iloc[train_index]\n",
    "    X_enade_treino = enade_treino.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_treino = enade_treino.iloc[:, -1]\n",
    "\n",
    "    enade_teste = dados_2017_2021.iloc[test_index]\n",
    "    X_enade_teste = enade_teste.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_teste = enade_teste.iloc[:, -1]\n",
    "    \n",
    "    normalizador_treinamento = StandardScaler()\n",
    "    normalizador_treinamento.fit(X_enade_treino)\n",
    "    treinamento_normalizado = normalizador_treinamento.transform(X_enade_treino)\n",
    "    \n",
    "    normalizador_teste = StandardScaler()\n",
    "    normalizador_teste.fit(X_enade_teste)\n",
    "    teste_normalizado = normalizador_teste.transform(X_enade_teste)\n",
    "    \n",
    "    model = HistGradientBoostingClassifier(max_depth=2, max_iter=10, random_state=42)\n",
    "    model.fit(treinamento_normalizado, y_enade_treino)\n",
    "    \n",
    "    result = permutation_importance(model, teste_normalizado, y_enade_teste, scoring=\"accuracy\",\n",
    "                            n_repeats=30,\n",
    "                            random_state=42)\n",
    "\n",
    "    feature_importance = result.importances_mean\n",
    "    total = feature_importance.sum()\n",
    "    feature_importance = feature_importance / total\n",
    "        \n",
    "    # importances_mean: Mean of feature importance over n_repeats.\n",
    "    # importances_std: Standard deviation over n_repeats.\n",
    "    # argsort: retorna uma lista com os indices correspondentes ao resultado da ordenação por valor, do array em questão\n",
    "    # [::-1]: retorna a lista na ordem inversa\n",
    "    # [:5]: Os cinco primeiros elementos\n",
    "    print(f\"\\nFolder {i}\")\n",
    "    for i in feature_importance.argsort()[::-1][0:5]:\n",
    "        print(f\"Atributo: {lista_caracteristicas[i]}\"\n",
    "              f\"\\n\\tMédia: {feature_importance[i]:.3f}\")\n",
    "        \n",
    "    y_score_teste = model.predict_proba(teste_normalizado)[:, 1]\n",
    "    auc = roc_auc_score(y_enade_teste, y_score_teste)\n",
    "    drift = max(2 * auc - 1, 0)\n",
    "    \n",
    "    media_auc += auc\n",
    "    media_drift += drift\n",
    "\n",
    "    print(f\"AUC score: {auc}\")\n",
    "    print(f\"Drift score: {drift}\")\n",
    "    \n",
    "print(\"\\nMédias das iterações\")\n",
    "print(f\"AUC score: {media_auc/5}\")\n",
    "print(f\"Drift score: {media_drift/5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
