{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a2e3ff-80ff-4cd2-a181-5be13523e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f043ec91-b746-4bd5-bf6e-9300b7242b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4878684c-5b69-40aa-9930-4a5db4db8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "enade_treino = pd.read_csv(\"../../concept_drift/tabela_final_2017_tres_anos_treinamento.csv\")\n",
    "enade_treino[\"origin\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3886c93-a7a4-4333-b524-ff0077857611",
   "metadata": {},
   "outputs": [],
   "source": [
    "enade_teste = pd.read_csv(\"../../concept_drift/tabela_final_2021_tres_anos_treinamento.csv\")\n",
    "enade_teste[\"origin\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cc5a3c0-7887-4998-96dd-40a7e5e0139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_Notas_Invalidas</th>\n",
       "      <th>Numero_Faltantes</th>\n",
       "      <th>Numero_Participantes</th>\n",
       "      <th>ADS</th>\n",
       "      <th>BCC</th>\n",
       "      <th>EC</th>\n",
       "      <th>GTI</th>\n",
       "      <th>LCC</th>\n",
       "      <th>RC</th>\n",
       "      <th>SI</th>\n",
       "      <th>...</th>\n",
       "      <th>Disc. totalmente.41</th>\n",
       "      <th>Discordo.41</th>\n",
       "      <th>Disc. parc..41</th>\n",
       "      <th>Concordo parc..41</th>\n",
       "      <th>Concordo.41</th>\n",
       "      <th>Concordo Total..41</th>\n",
       "      <th>Não sei responder.41</th>\n",
       "      <th>Não se aplica.43</th>\n",
       "      <th>Nota_Conceito_Faixa</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Numero_Notas_Invalidas  Numero_Faltantes  Numero_Participantes  ADS  \\\n",
       "3                        0.0          0.184615              0.815385  0.0   \n",
       "947                      0.0          0.000000              1.000000  1.0   \n",
       "1174                     0.0          0.277778              0.722222  0.0   \n",
       "476                      0.0          0.000000              1.000000  0.0   \n",
       "415                      0.0          0.423077              0.576923  1.0   \n",
       "\n",
       "      BCC   EC  GTI  LCC   RC   SI  ...  Disc. totalmente.41  Discordo.41  \\\n",
       "3     1.0  0.0  0.0  0.0  0.0  0.0  ...             0.046154     0.061538   \n",
       "947   0.0  0.0  0.0  0.0  0.0  0.0  ...             0.000000     0.000000   \n",
       "1174  0.0  0.0  0.0  0.0  0.0  1.0  ...             0.111111     0.333333   \n",
       "476   0.0  0.0  0.0  0.0  0.0  1.0  ...             0.000000     0.000000   \n",
       "415   0.0  0.0  0.0  0.0  0.0  0.0  ...             0.000000     0.076923   \n",
       "\n",
       "      Disc. parc..41  Concordo parc..41  Concordo.41  Concordo Total..41  \\\n",
       "3           0.076923           0.292308     0.138462            0.215385   \n",
       "947         0.000000           0.000000     0.000000            1.000000   \n",
       "1174        0.222222           0.000000     0.111111            0.055556   \n",
       "476         0.000000           0.000000     0.142857            0.785714   \n",
       "415         0.051282           0.115385     0.243590            0.243590   \n",
       "\n",
       "      Não sei responder.41  Não se aplica.43  Nota_Conceito_Faixa  origin  \n",
       "3                 0.000000          0.000000                    3       0  \n",
       "947               0.000000          0.000000                    3       0  \n",
       "1174              0.000000          0.055556                    3       0  \n",
       "476               0.071429          0.000000                    3       1  \n",
       "415               0.025641          0.012821                    4       1  \n",
       "\n",
       "[5 rows x 641 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_2017_2021 = pd.concat([enade_treino, enade_teste])\n",
    "\n",
    "# No NannyML parece que não randomiza por causa da separação em chunks\n",
    "#dados_2017_2021 = dados_2017_2021.sample(frac = 1, ignore_index=True)\n",
    "\n",
    "dados_2017_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1868a77f-1381-4285-b978-04e742e94faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_caracteristicas = dados_2017_2021.shape[1] - 1\n",
    "X_enade = dados_2017_2021.iloc[:, 0:numero_caracteristicas]\n",
    "y_enade = dados_2017_2021.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282b726a-4175-477d-8657-c5c8cef7f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_caracteristicas = enade_treino.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d838c31-0224-4654-9ab9-0d2bc072a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder 0\n",
      "AUC score: 0.9135384647229898\n",
      "\n",
      "Folder 1\n",
      "AUC score: 0.9056105815505946\n",
      "\n",
      "Folder 2\n",
      "AUC score: 0.9214352987445793\n",
      "\n",
      "Folder 3\n",
      "AUC score: 0.8872501837074755\n",
      "\n",
      "Folder 4\n",
      "AUC score: 0.9025367156208277\n",
      "\n",
      "Folder 5\n",
      "AUC score: 0.9031990975046833\n",
      "\n",
      "Folder 6\n",
      "AUC score: 0.9146251850011902\n",
      "\n",
      "Folder 7\n",
      "AUC score: 0.9317746659628858\n",
      "\n",
      "Folder 8\n",
      "AUC score: 0.9164260357479224\n",
      "\n",
      "Folder 9\n",
      "AUC score: 0.9157533041471316\n",
      "\n",
      "AUC score Total: 0.9108705146914231\n"
     ]
    }
   ],
   "source": [
    "# NannyML approach\n",
    "\n",
    "stratifiedSplit = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "y_true_splits = []\n",
    "y_score_splits = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratifiedSplit.split(X_enade, y_enade)):\n",
    "    enade_treino = dados_2017_2021.iloc[train_index]\n",
    "    X_enade_treino = enade_treino.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_treino = enade_treino.iloc[:, -1]\n",
    "\n",
    "    enade_teste = dados_2017_2021.iloc[test_index]\n",
    "    X_enade_teste = enade_teste.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_teste = enade_teste.iloc[:, -1]\n",
    "    \n",
    "    normalizador_treinamento = StandardScaler()\n",
    "    normalizador_treinamento.fit(X_enade_treino)\n",
    "    treinamento_normalizado = normalizador_treinamento.transform(X_enade_treino)\n",
    "    \n",
    "    normalizador_teste = StandardScaler()\n",
    "    normalizador_teste.fit(X_enade_teste)\n",
    "    teste_normalizado = normalizador_teste.transform(X_enade_teste)\n",
    "    \n",
    "    # LGBMClassifier é o modelo utilizado na biblioteca NannyML\n",
    "    lgbmClassifier = LGBMClassifier(objective='binary', importance_type='split', boosting_type='gbdt', num_leaves=31, learning_rate=0.05, \n",
    "                                    feature_fraction=0.9, bagging_fraction=0.8, bagging_freq=5, colsample_bytree=None, subsample_freq=None, subsample=None)\n",
    "    lgbmClassifier.fit(treinamento_normalizado, y_enade_treino)\n",
    "            \n",
    "    y_score_teste = lgbmClassifier.predict_proba(teste_normalizado)[:, 1]\n",
    "    \n",
    "    y_true_splits.extend(y_enade_teste)\n",
    "    y_score_splits.extend(y_score_teste)\n",
    "    \n",
    "    print(f\"\\nFolder {i}\")\n",
    "    print(f\"AUC score: {roc_auc_score(y_enade_teste, y_score_teste)}\")\n",
    "\n",
    "result = roc_auc_score(y_true_splits, y_score_splits)\n",
    "print(f\"\\nAUC score Total: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6904da-dbfd-406c-a75a-172e1870c6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder 0\n",
      "Atributo: Nenhum.2\n",
      "\tMédia: 0.408\n",
      "Atributo: Não sei responder.26\n",
      "\tMédia: 0.220\n",
      "Atributo: Disc. totalmente.38\n",
      "\tMédia: 0.080\n",
      "Atributo: Não sei responder.41\n",
      "\tMédia: 0.072\n",
      "Atributo: Prog CSF\n",
      "\tMédia: 0.071\n",
      "AUC score: 0.8111120821297813\n",
      "Drift score: 0.6222241642595625\n",
      "\n",
      "Folder 1\n",
      "Atributo: Nenhum.2\n",
      "\tMédia: 0.408\n",
      "Atributo: Não sei responder.26\n",
      "\tMédia: 0.267\n",
      "Atributo: Disc. totalmente.38\n",
      "\tMédia: 0.135\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.095\n",
      "Atributo: Prog CSF\n",
      "\tMédia: 0.034\n",
      "AUC score: 0.7946180523614151\n",
      "Drift score: 0.5892361047228303\n",
      "\n",
      "Folder 2\n",
      "Atributo: Nenhum.2\n",
      "\tMédia: 0.398\n",
      "Atributo: Não sei responder.26\n",
      "\tMédia: 0.213\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.136\n",
      "Atributo: Não sei responder.34\n",
      "\tMédia: 0.062\n",
      "Atributo: Disc. totalmente.38\n",
      "\tMédia: 0.062\n",
      "AUC score: 0.7954045774842234\n",
      "Drift score: 0.5908091549684469\n",
      "\n",
      "Folder 3\n",
      "Atributo: Nenhum.2\n",
      "\tMédia: 0.379\n",
      "Atributo: Não sei responder.26\n",
      "\tMédia: 0.243\n",
      "Atributo: Não se aplica.36\n",
      "\tMédia: 0.119\n",
      "Atributo: Prog CSF\n",
      "\tMédia: 0.085\n",
      "Atributo: Disc. totalmente.38\n",
      "\tMédia: 0.053\n",
      "AUC score: 0.8008343605688739\n",
      "Drift score: 0.6016687211377478\n",
      "\n",
      "Folder 4\n",
      "Atributo: Nenhum.2\n",
      "\tMédia: 0.400\n",
      "Atributo: Não sei responder.26\n",
      "\tMédia: 0.238\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.115\n",
      "Atributo: Disc. totalmente.38\n",
      "\tMédia: 0.085\n",
      "Atributo: Não sei responder.34\n",
      "\tMédia: 0.069\n",
      "AUC score: 0.7900322889260942\n",
      "Drift score: 0.5800645778521885\n",
      "\n",
      "Médias das iterações\n",
      "AUC score: 0.7984002722940776\n",
      "Drift score: 0.5968005445881552\n",
      "Nenhum: 0.0\n",
      "Não sei responder.2: 0.0\n",
      "Numero_Participantes: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Deepchecks approach\n",
    "\n",
    "stratifiedSplit = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "top_3 = [0, 0, 0]\n",
    "media_auc = 0\n",
    "media_drift = 0\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratifiedSplit.split(X_enade, y_enade)):\n",
    "    enade_treino = dados_2017_2021.iloc[train_index]\n",
    "    X_enade_treino = enade_treino.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_treino = enade_treino.iloc[:, -1]\n",
    "\n",
    "    enade_teste = dados_2017_2021.iloc[test_index]\n",
    "    X_enade_teste = enade_teste.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_teste = enade_teste.iloc[:, -1]\n",
    "    \n",
    "    normalizador_treinamento = StandardScaler()\n",
    "    normalizador_treinamento.fit(X_enade_treino)\n",
    "    treinamento_normalizado = normalizador_treinamento.transform(X_enade_treino)\n",
    "    \n",
    "    normalizador_teste = StandardScaler()\n",
    "    normalizador_teste.fit(X_enade_teste)\n",
    "    teste_normalizado = normalizador_teste.transform(X_enade_teste)\n",
    "    \n",
    "    model = HistGradientBoostingClassifier(max_depth=2, max_iter=10, random_state=42)\n",
    "    model.fit(treinamento_normalizado, y_enade_treino)\n",
    "    \n",
    "    result = permutation_importance(model, teste_normalizado, y_enade_teste, scoring=\"accuracy\",\n",
    "                            n_repeats=30,\n",
    "                            random_state=42)\n",
    "\n",
    "    feature_importance = result.importances_mean\n",
    "    total = feature_importance.sum()\n",
    "    feature_importance = feature_importance / total\n",
    "        \n",
    "    # importances_mean: Mean of feature importance over n_repeats.\n",
    "    # importances_std: Standard deviation over n_repeats.\n",
    "    # argsort: retorna uma lista com os indices correspondentes ao resultado da ordenação por valor, do array em questão\n",
    "    # [::-1]: retorna a lista na ordem inversa\n",
    "    # [:5]: Os cinco primeiros elementos\n",
    "    print(f\"\\nFolder {i}\")\n",
    "    for i in feature_importance.argsort()[::-1][0:5]:\n",
    "        print(f\"Atributo: {lista_caracteristicas[i]}\"\n",
    "              f\"\\n\\tMédia: {feature_importance[i]:.3f}\")\n",
    "        \n",
    "    y_score_teste = model.predict_proba(teste_normalizado)[:, 1]\n",
    "    auc = roc_auc_score(y_enade_teste, y_score_teste)\n",
    "    drift = max(2 * auc - 1, 0)\n",
    "    \n",
    "    media_auc += auc\n",
    "    media_drift += drift\n",
    "\n",
    "    print(f\"AUC score: {auc}\")\n",
    "    print(f\"Drift score: {drift}\")\n",
    "    \n",
    "print(\"\\nMédias das iterações\")\n",
    "print(f\"AUC score: {media_auc/5}\")\n",
    "print(f\"Drift score: {media_drift/5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
