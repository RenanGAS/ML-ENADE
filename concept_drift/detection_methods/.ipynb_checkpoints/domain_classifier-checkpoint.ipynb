{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3a2e3ff-80ff-4cd2-a181-5be13523e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f043ec91-b746-4bd5-bf6e-9300b7242b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4878684c-5b69-40aa-9930-4a5db4db8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "enade_treino = pd.read_csv(\"../../concept_drift/tabela_final_2017_treinamento.csv\")\n",
    "enade_treino[\"origin\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c3886c93-a7a4-4333-b524-ff0077857611",
   "metadata": {},
   "outputs": [],
   "source": [
    "enade_teste = pd.read_csv(\"../../concept_drift/tabela_final_2021_treinamento.csv\")\n",
    "enade_teste[\"origin\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7cc5a3c0-7887-4998-96dd-40a7e5e0139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numero_Notas_Invalidas</th>\n",
       "      <th>Numero_Faltantes</th>\n",
       "      <th>Numero_Participantes</th>\n",
       "      <th>nulos_UF_Ensino_Medio</th>\n",
       "      <th>RO</th>\n",
       "      <th>AC</th>\n",
       "      <th>AM</th>\n",
       "      <th>RR</th>\n",
       "      <th>PA</th>\n",
       "      <th>AP</th>\n",
       "      <th>...</th>\n",
       "      <th>Não sei responder.4</th>\n",
       "      <th>nulos_Formacao</th>\n",
       "      <th>Muito boa</th>\n",
       "      <th>Boa</th>\n",
       "      <th>Regular</th>\n",
       "      <th>Fraca</th>\n",
       "      <th>Muito fraca</th>\n",
       "      <th>Não sei responder.5</th>\n",
       "      <th>Nota_Conceito_Faixa</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265823</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.177215</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Numero_Notas_Invalidas  Numero_Faltantes  Numero_Participantes  \\\n",
       "0                     0.0          0.043478              0.956522   \n",
       "1                     0.0          0.265823              0.734177   \n",
       "2                     0.0          0.205128              0.794872   \n",
       "3                     0.0          0.184615              0.815385   \n",
       "4                     0.0          0.000000              1.000000   \n",
       "\n",
       "   nulos_UF_Ensino_Medio        RO   AC        AM   RR        PA   AP  ...  \\\n",
       "0               0.043478  0.043478  0.0  0.000000  0.0  0.043478  0.0  ...   \n",
       "1               0.316456  0.000000  0.0  0.000000  0.0  0.000000  0.0  ...   \n",
       "2               0.256410  0.000000  0.0  0.025641  0.0  0.000000  0.0  ...   \n",
       "3               0.169231  0.000000  0.0  0.000000  0.0  0.000000  0.0  ...   \n",
       "4               0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  ...   \n",
       "\n",
       "   Não sei responder.4  nulos_Formacao  Muito boa       Boa   Regular  \\\n",
       "0             0.043478        0.043478   0.304348  0.434783  0.217391   \n",
       "1             0.025316        0.316456   0.126582  0.177215  0.316456   \n",
       "2             0.000000        0.256410   0.256410  0.256410  0.205128   \n",
       "3             0.000000        0.169231   0.261538  0.215385  0.276923   \n",
       "4             0.038462        0.000000   0.230769  0.461538  0.269231   \n",
       "\n",
       "      Fraca  Muito fraca  Não sei responder.5  Nota_Conceito_Faixa  origin  \n",
       "0  0.000000     0.000000             0.000000                    3       0  \n",
       "1  0.037975     0.012658             0.012658                    4       0  \n",
       "2  0.000000     0.000000             0.025641                    4       0  \n",
       "3  0.030769     0.030769             0.015385                    3       0  \n",
       "4  0.038462     0.000000             0.000000                    5       0  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_2017_2021 = pd.concat([enade_treino, enade_teste])\n",
    "\n",
    "# No NannyML parece que não randomiza por causa da separção em chunks\n",
    "#dados_2017_2021 = dados_2017_2021.sample(frac = 1, ignore_index=True)\n",
    "\n",
    "dados_2017_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1868a77f-1381-4285-b978-04e742e94faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_caracteristicas = dados_2017_2021.shape[1] - 1\n",
    "X_enade = dados_2017_2021.iloc[:, 0:numero_caracteristicas]\n",
    "y_enade = dados_2017_2021.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "282b726a-4175-477d-8657-c5c8cef7f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_caracteristicas = enade_treino.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5d838c31-0224-4654-9ab9-0d2bc072a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder 0\n",
      "AUC score: 0.8729137009758412\n",
      "\n",
      "Folder 1\n",
      "AUC score: 0.8714179612551836\n",
      "\n",
      "Folder 2\n",
      "AUC score: 0.8824554888490024\n",
      "\n",
      "Folder 3\n",
      "AUC score: 0.8569866518124241\n",
      "\n",
      "Folder 4\n",
      "AUC score: 0.8896040931691115\n",
      "\n",
      "AUC score Total: 0.8745018670957891\n"
     ]
    }
   ],
   "source": [
    "# NannyML approach\n",
    "\n",
    "stratifiedSplit = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "y_true_splits = []\n",
    "y_score_splits = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratifiedSplit.split(X_enade, y_enade)):\n",
    "    enade_treino = dados_2017_2021.iloc[train_index]\n",
    "    X_enade_treino = enade_treino.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_treino = enade_treino.iloc[:, -1]\n",
    "\n",
    "    enade_teste = dados_2017_2021.iloc[test_index]\n",
    "    X_enade_teste = enade_teste.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_teste = enade_teste.iloc[:, -1]\n",
    "    \n",
    "    normalizador_treinamento = StandardScaler()\n",
    "    normalizador_treinamento.fit(X_enade_treino)\n",
    "    treinamento_normalizado = normalizador_treinamento.transform(X_enade_treino)\n",
    "    \n",
    "    normalizador_teste = StandardScaler()\n",
    "    normalizador_teste.fit(X_enade_teste)\n",
    "    teste_normalizado = normalizador_teste.transform(X_enade_teste)\n",
    "    \n",
    "#    parametros_para_busca = {\n",
    "#    'boosting_type': ['gbdt', 'dart', 'rf'],\n",
    "#    'num_leaves': [21, 31, 51, 91, 131],\n",
    "#    'learning_rate': [0.01, 0.05, 0.1],\n",
    "#    # porcentagem de features para usar\n",
    "#    'feature_fraction': [0.7, 0.8, 0.9],\n",
    "#    # porcentagem de dados para usar em cada bagging\n",
    "#    'bagging_fraction': [0.6, 0.7, 0.8],\n",
    "#    # número de iterações até o próximo bagging\n",
    "#    'bagging_freq': [2, 3, 5],\n",
    "#    }\n",
    "\n",
    "#    busca = HalvingGridSearchCV(lgbmClassifier, parametros_para_busca, scoring=\"f1\").fit(treinamento_normalizado, y_enade_treino) \n",
    "#    estimator = busca.best_estimator_\n",
    "    \n",
    "    # LGBMClassifier é o modelo utilizado na biblioteca NannyML\n",
    "    lgbmClassifier = LGBMClassifier(objective='binary', importance_type='split', boosting_type='gbdt', num_leaves=31, learning_rate=0.05, \n",
    "                                    feature_fraction=0.9, bagging_fraction=0.8, bagging_freq=5, colsample_bytree=None, subsample_freq=None, subsample=None)\n",
    "    lgbmClassifier.fit(treinamento_normalizado, y_enade_treino)\n",
    "            \n",
    "    y_score_teste = lgbmClassifier.predict_proba(teste_normalizado)[:, 1]\n",
    "    \n",
    "    y_true_splits.extend(y_enade_teste)\n",
    "    y_score_splits.extend(y_score_teste)\n",
    "    \n",
    "    print(f\"\\nFolder {i}\")\n",
    "    print(f\"AUC score: {roc_auc_score(y_enade_teste, y_score_teste)}\")\n",
    "\n",
    "result = roc_auc_score(y_true_splits, y_score_splits)\n",
    "print(f\"\\nAUC score Total: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0b6904da-dbfd-406c-a75a-172e1870c6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder 0\n",
      "Atributo: Nenhum\n",
      "\tMédia: 0.399\n",
      "Atributo: Não sei responder.2\n",
      "\tMédia: 0.289\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.158\n",
      "AUC score: 0.7706275474608012\n",
      "Drift score: 0.5412550949216024\n",
      "\n",
      "Folder 1\n",
      "Atributo: Nenhum\n",
      "\tMédia: 0.526\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.259\n",
      "Atributo: Não sei responder.2\n",
      "\tMédia: 0.191\n",
      "AUC score: 0.7639880843094774\n",
      "Drift score: 0.5279761686189548\n",
      "\n",
      "Folder 2\n",
      "Atributo: Nenhum\n",
      "\tMédia: 0.450\n",
      "Atributo: Não sei responder.2\n",
      "\tMédia: 0.285\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.187\n",
      "AUC score: 0.7612730877978923\n",
      "Drift score: 0.5225461755957845\n",
      "\n",
      "Folder 3\n",
      "Atributo: Nenhum\n",
      "\tMédia: 0.530\n",
      "Atributo: Não sei responder.2\n",
      "\tMédia: 0.256\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.090\n",
      "AUC score: 0.763561212499541\n",
      "Drift score: 0.527122424999082\n",
      "\n",
      "Folder 4\n",
      "Atributo: Nenhum\n",
      "\tMédia: 0.416\n",
      "Atributo: Numero_Participantes\n",
      "\tMédia: 0.226\n",
      "Atributo: Não sei responder.2\n",
      "\tMédia: 0.223\n",
      "AUC score: 0.7499173796496897\n",
      "Drift score: 0.4998347592993795\n",
      "\n",
      "Médias das iterações\n",
      "AUC score: 0.7618734623434803\n",
      "Drift score: 0.5237469246869606\n",
      "Nenhum: 0.46411385991557486\n",
      "Não sei responder.2: 0.24873319640067923\n",
      "Numero_Participantes: 0.18405074265208077\n"
     ]
    }
   ],
   "source": [
    "# NannyML approach\n",
    "\n",
    "stratifiedSplit = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "top_3 = [0, 0, 0]\n",
    "media_auc = 0\n",
    "media_drift = 0\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratifiedSplit.split(X_enade, y_enade)):\n",
    "    enade_treino = dados_2017_2021.iloc[train_index]\n",
    "    X_enade_treino = enade_treino.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_treino = enade_treino.iloc[:, -1]\n",
    "\n",
    "    enade_teste = dados_2017_2021.iloc[test_index]\n",
    "    X_enade_teste = enade_teste.iloc[:, 0:numero_caracteristicas]\n",
    "    y_enade_teste = enade_teste.iloc[:, -1]\n",
    "    \n",
    "    normalizador_treinamento = StandardScaler()\n",
    "    normalizador_treinamento.fit(X_enade_treino)\n",
    "    treinamento_normalizado = normalizador_treinamento.transform(X_enade_treino)\n",
    "    \n",
    "    normalizador_teste = StandardScaler()\n",
    "    normalizador_teste.fit(X_enade_teste)\n",
    "    teste_normalizado = normalizador_teste.transform(X_enade_teste)\n",
    "    \n",
    "#    parametros_para_busca = {\n",
    "#    'boosting_type': ['gbdt', 'dart', 'rf'],\n",
    "#    'num_leaves': [21, 31, 51, 91, 131],\n",
    "#    'learning_rate': [0.01, 0.05, 0.1],\n",
    "#    # porcentagem de features para usar\n",
    "#    'feature_fraction': [0.7, 0.8, 0.9],\n",
    "#    # porcentagem de dados para usar em cada bagging\n",
    "#    'bagging_fraction': [0.6, 0.7, 0.8],\n",
    "#    # número de iterações até o próximo bagging\n",
    "#    'bagging_freq': [2, 3, 5],\n",
    "#    }\n",
    "\n",
    "#    busca = HalvingGridSearchCV(lgbmClassifier, parametros_para_busca, scoring=\"f1\").fit(treinamento_normalizado, y_enade_treino) \n",
    "#    estimator = busca.best_estimator_\n",
    "    \n",
    "    model = HistGradientBoostingClassifier(max_depth=2, max_iter=10, random_state=42)\n",
    "    model.fit(treinamento_normalizado, y_enade_treino)\n",
    "    \n",
    "    result = permutation_importance(model, teste_normalizado, y_enade_teste, scoring=\"accuracy\",\n",
    "                            n_repeats=30,\n",
    "                            random_state=42)\n",
    "\n",
    "    feature_importance = result.importances_mean\n",
    "    total = feature_importance.sum()\n",
    "    feature_importance = feature_importance / total\n",
    "        \n",
    "    # importances_mean: Mean of feature importance over n_repeats.\n",
    "    # importances_std: Standard deviation over n_repeats.\n",
    "    # argsort: retorna uma lista com os indices correspondentes ao resultado da ordenação por valor, do array em questão\n",
    "    # [::-1]: retorna a lista na ordem inversa\n",
    "    # [:5]: Os cinco primeiros elementos\n",
    "    print(f\"\\nFolder {i}\")\n",
    "    for i in feature_importance.argsort()[::-1][0:10]:\n",
    "        match lista_caracteristicas[i]:\n",
    "            case \"Nenhum\":\n",
    "                print(f\"Atributo: {lista_caracteristicas[i]}\"\n",
    "                      f\"\\n\\tMédia: {feature_importance[i]:.3f}\")\n",
    "                \n",
    "                top_3[0] += feature_importance[i]\n",
    "            case \"Não sei responder.2\":\n",
    "                print(f\"Atributo: {lista_caracteristicas[i]}\"\n",
    "                      f\"\\n\\tMédia: {feature_importance[i]:.3f}\")\n",
    "                \n",
    "                top_3[1] += feature_importance[i]\n",
    "            case \"Numero_Participantes\":\n",
    "                print(f\"Atributo: {lista_caracteristicas[i]}\"\n",
    "                      f\"\\n\\tMédia: {feature_importance[i]:.3f}\")\n",
    "                \n",
    "                top_3[2] += feature_importance[i]\n",
    "        \n",
    "    \n",
    "    y_score_teste = model.predict_proba(teste_normalizado)[:, 1]\n",
    "    auc = roc_auc_score(y_enade_teste, y_score_teste)\n",
    "    drift = max(2 * auc - 1, 0)\n",
    "    \n",
    "    media_auc += auc\n",
    "    media_drift += drift\n",
    "\n",
    "    print(f\"AUC score: {auc}\")\n",
    "    print(f\"Drift score: {drift}\")\n",
    "    \n",
    "print(\"\\nMédias das iterações\")\n",
    "print(f\"AUC score: {media_auc/5}\")\n",
    "print(f\"Drift score: {media_drift/5}\")\n",
    "print(f\"Nenhum: {top_3[0]/5}\")\n",
    "print(f\"Não sei responder.2: {top_3[1]/5}\")\n",
    "print(f\"Numero_Participantes: {top_3[2]/5}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
